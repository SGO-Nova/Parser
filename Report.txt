Blake McLaughlin, Ryan Browning
Group 34
Report

1)    Data Structures:
    Linked-Lists: We used the linked lists to operate as tokens in order to set up the necessary tokens to represent the context-free-grammer used by the parser.

    Multi-child Tree: This tree will be used primarily in the Tree_Process & Create_Token functions where we create and functionalize the tokenizer tree. 

    Arrays: Required in order to store the contents from the txt file.

    Queue: The queue is used in order to temporarily store the recorded data from the tokenizer tree until they are ready to be printed out.

 2)    Functions:
     Tokenizer(int state, char character, char token [])
     Main Function: 
     Data: int argc, char argv[]
     Purpose: The purpose of the main function is to take the txt file that needs to be read and send it through the token tree, starting the token push.
     Expected Output: 

     Function 1_Parse Error - 
     Data:
     Purpose: The parse error function will need to come into play when there's an error in the parsing section of the program.
     Expected Output:

     Function 2_recursionXML - 
     Data: int state
     Purpose: The recursion function is going to be built to make nine different cases built to give the tokens names depending on the order that they go into the token tree.
     Expected Output:

     Function 3_Scan - 
     Data: char *file
     Purpose: The scan function is built to open and read the .txt test file and push the contents onto the Interpreter function.
     Expected Output:

     Function 4_Interpreter - 
     Data: char character[], char next
     Purpose: The interpreter function is required in order to take the individual nodes and set individual signs throughout the tokenizer tree which will also attribute the values across the tree.
     Expected Output:

     Function 5_Tree_Create - 
     Data: int state, char character[10], int terminator
     Purpose: The purpose of this function is to build a token tree that will pass tokens based off the .txt reading file in order to build the expected output.
     Expected Output:

     Function 6_Tree_Process - 
     Data: 
     Purpose: The tree process function will help formulate the flow between node to node in the tokenizer tree, it is required in order to tell the program which node comes next in the tree.
     Expected Output:

     Function 7_Create_Token -     
     Data: char token_type[10]
     Purpose: The purpose of this function will be to create the actual tokens that will go through the token tree, and end up representing the parser's finalized output.
     Expected Output:

     Function 8_Push - 
     Data: char id[99]
     Purpose: The push and pop function will be designated to act as a queue for the tokens in their final stage before being outputted as a parser.
     Expected Output:

     Function 9_pop:
     Data:
     Purpose: The pop function will simply need to be able to output each in the required order to formulate the parser from the queue.
     Expected Output:
     
  Psuedocode:
  

  3)   Test files:
  I)
     // This test text should give out: (read, id, id, assign, number, div, id, write, id)
     x := 5
  II)  
     //This coude should give out: (lparen, id, assign, number, rparen, id, assign, number, minus, id, times, lparen, number,       div, number, rparen)
     read A
  III)
     //This code should give out: PARSE ERROR
     x = 5
  IV)
     //This code should give out: (number, plus, number)
     3+4.2
  V)
     /*

     Test multiple lines comments

     */
     read x
     write y

  4)   Acknoledgement: N/A
  
  
  
